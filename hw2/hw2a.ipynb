{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[]},"gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# HW2A: Alignment with IBM Model 1\n"],"metadata":{"_kg_hide-output":true,"id":"SbbJcFxKuPdj"}},{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import math\n","import matplotlib.pyplot as plt # graphs and figures\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import string\n","from collections import Counter\n","from itertools import product\n","import tqdm.notebook\n","import pickle\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-11T20:25:09.64378Z","iopub.execute_input":"2022-02-11T20:25:09.644101Z","iopub.status.idle":"2022-02-11T20:25:09.651999Z","shell.execute_reply.started":"2022-02-11T20:25:09.644071Z","shell.execute_reply":"2022-02-11T20:25:09.650789Z"},"trusted":true,"id":"RbrdQqdRuPdl","executionInfo":{"status":"ok","timestamp":1677477297470,"user_tz":480,"elapsed":2431,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Data\n","\n","We'll start out by using a toy dataset. Please see [these slides](https://cal-cs288.github.io/sp20/slides/cs288_sp20_05_statistical_translation_4up.pdf) for a more complete coverage of IBM Model 1, and feel free to check out Philipp Koehn's book _Statistical Machine Translation_. "],"metadata":{"id":"4ROT120tuPdm"}},{"cell_type":"code","source":["aligned_data = [\n","    ([\"das\", \"haus\"], [\"the\", \"house\"]),\n","    ([\"das\", \"buch\"], [\"the\", \"book\"]),\n","    ([\"ein\", \"buch\"], [\"a\", \"book\"]),\n","]"],"metadata":{"execution":{"iopub.status.busy":"2022-02-11T20:27:06.436853Z","iopub.execute_input":"2022-02-11T20:27:06.438933Z","iopub.status.idle":"2022-02-11T20:27:06.451573Z","shell.execute_reply.started":"2022-02-11T20:27:06.438872Z","shell.execute_reply":"2022-02-11T20:27:06.450641Z"},"trusted":true,"id":"5nJZnJGDuPdm","executionInfo":{"status":"ok","timestamp":1677477302160,"user_tz":480,"elapsed":184,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Alignment Model\n","\n","Fill in the code for IBM Model 1 below. A correct implementation should achieve perplexity 4096 on the first iteration and perplexity around 70 by the tenth iteration, for the toy dataset above. Note that we'll be grading you only on the generated `self.translation_probabilities`, so the probability and perplexity functions only exist for you to check the correctness of your own implementation. You may wish to comment them out during implementation and check that `self.translation_probabilities` looks reasonable instead."],"metadata":{"id":"vNNKfZ-BuPdm"}},{"cell_type":"code","source":["import numpy as np\n","\n","class IBMModel1:\n","    def __init__(self, data, num_iterations=10, epsilon=1.0, compute_perplexity=True):\n","        self.data = data # aligned corpus as shown above\n","        self.num_iterations = num_iterations # iterations of expectation-maximization\n","        self.epsilon = epsilon\n","        self.compute_perplexity = compute_perplexity\n","        \n","        # Preprocess bitext data:\n","        self.source_words, self.target_words = set(), set()\n","        for (source, target) in self.data:\n","            self.source_words.update(source)\n","            self.target_words.update(target)\n","        \n","        # Initialize uniform probabilities:\n","        self.translation_probs = {(s, t): 1.0/len(self.target_words)\n","                                  for s,t in product(self.source_words, self.target_words)}\n","        \n","        # print(self.source_words)\n","        # print(self.target_words)\n","        \n","    def e_step(self):\n","        # YOUR SOLUTION HERE\n","        # - Iterate over paired sentences in the data and compute:\n","        # - (1) counts, the number of times a source word is translated into a target word,\n","        #       weighted by alignment probabilities\n","        # - (2) total, the sum of counts over all possible target words\n","        # See slide 32 for more information: https://cal-cs288.github.io/sp20/slides/cs288_sp20_05_statistical_translation_4up.pdf\n","        # BEGIN SOLUTION\n","\n","        counts = {(s, t): 0 for s, t in product(self.source_words, self.target_words)}\n","        total = {s: 0 for s in self.source_words}\n","\n","        for (source, target) in self.data:\n","            s_total_t = {}\n","            for t in target:\n","                s_total_t[t] = 0\n","                for s in source:\n","                    s_total_t[t] += self.translation_probs[(s, t)]\n","            for t in target:\n","                for s in source:\n","                    add = self.translation_probs[(s, t)] / s_total_t[t]\n","                    counts[(s, t)] = counts.get((s, t), 0) + add\n","                    total[s] = total.get(s, 0) + add\n","\n","        return counts, total\n","        # END SOLUTION\n","        \n","    def m_step(self, counts, total):\n","        # YOUR SOLUTION HERE\n","        # - Update self.translation_probs using counts and total\n","        # BEGIN SOLUTION\n","        for t in self.target_words:\n","            for s in self.source_words:\n","                self.translation_probs[(s, t)] = counts.get((s, t), 0) / total[s]\n","        # END SOLUTION\n","        \n","    def train(self):\n","        # Run EM for self.num_iterations:\n","        for idx in tqdm.tqdm(range(self.num_iterations)):\n","            if self.compute_perplexity: \n","                print(\"Iteration: {} | Perplexity: {}\".format(idx, self.perplexity()))\n","            counts, total = self.e_step()\n","            self.m_step(counts, total)\n","        if self.compute_perplexity:\n","            print(\"Iteration: {} | Perplexity: {}\".format(self.num_iterations, self.perplexity()))\n","\n","    def probability(self, source, target):\n","        # YOUR SOLUTION HERE\n","        # - Use the normalization trick from lecture to efficiently compute probabilities\n","        # - We'll use self.epsilon here, which is defined in the initialization\n","        # BEGIN SOLUTION\n","        # norm = self.epsilon / (len(source) + 1) ** len(target)\n","        norm = self.epsilon / len(source) ** len(target)\n","        prob = 1\n","        for j in range(1, len(target)):\n","            sum = 0\n","            for i in range(len(source)):\n","                sum += self.translation_probs[(source[i], target[j])]\n","            prob *= sum\n","        return prob * norm\n","        # END SOLUTION\n","        \n","    def perplexity(self):\n","        # YOUR SOLUTION HERE\n","        # - Iterate over each pair of sentences in the dataset\n","        # - Call self.probability and compute a sum in log space\n","        # - Feel free to comment this out while testing your initial model\n","        # BEGIN SOLUTION\n","        log_probs = []\n","        for (source, target) in self.data:\n","            log_probs.append(-math.log(self.probability(source, target), 2))\n","        # return 2 ** np.mean(log_probs)\n","        return 2 ** np.sum(log_probs)\n","        # END SOLUTION\n","        \n","    def get_alignment(self, source, target):\n","        # YOUR SOLUTION HERE\n","        # - Find the best word alignment for a source, target pair\n","        # - Output a list of [(source_idx, target_idx)]\n","        #   For example: ([\"ein\", \"buch\"], [\"a\", \"book\"])\n","        #   should have an alignment [(0,0), (1,1)]\n","        # BEGIN SOLUTION\n","        alignment = []\n","        for i, s in enumerate(source):\n","            probs = []\n","            for j, t in enumerate(target):\n","                prob = self.translation_probs[(s, t)]\n","                probs.append(prob)\n","            alignment.append((i, np.argmax(probs)))\n","        return alignment\n","        # END SOLUTION\n","\n","ibm = IBMModel1(aligned_data)\n","# ibm.e_step()\n","ibm.train()\n","test_align = ibm.get_alignment([\"ein\", \"buch\"], [\"a\", \"book\"])\n","assert(test_align == [(0, 0), (1, 1)]), f\"incorrect alignment: {test_align}\"\n","with open(\"example_alignments.pkl\", \"wb\") as outfile:\n","    pickle.dump(ibm.translation_probs, outfile, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"execution":{"iopub.status.busy":"2022-02-11T20:27:18.353267Z","iopub.execute_input":"2022-02-11T20:27:18.353685Z","iopub.status.idle":"2022-02-11T20:27:18.384054Z","shell.execute_reply.started":"2022-02-11T20:27:18.353655Z","shell.execute_reply":"2022-02-11T20:27:18.38336Z"},"trusted":true,"id":"Ah1xi0KOuPdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677477303461,"user_tz":480,"elapsed":210,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"4d2b55cb-959c-4e8d-fab0-b41294c59de9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 1273.70it/s]"]},{"output_type":"stream","name":"stdout","text":["Iteration: 0 | Perplexity: 512.0\n","Iteration: 1 | Perplexity: 113.7777777777778\n","Iteration: 2 | Perplexity: 97.51462480142041\n","Iteration: 3 | Perplexity: 85.78196870733935\n","Iteration: 4 | Perplexity: 77.79096097780953\n","Iteration: 5 | Perplexity: 72.59043544199892\n","Iteration: 6 | Perplexity: 69.30530471868815\n","Iteration: 7 | Perplexity: 67.27067983454162\n","Iteration: 8 | Perplexity: 66.02699803455424\n","Iteration: 9 | Perplexity: 65.27284310122455\n","Iteration: 10 | Perplexity: 64.81686703974303\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Visualization and Analysis\n","\n","Write code to visualize alignments and rerun the IBM model on a (very slightly larger) toy dataset:"],"metadata":{"id":"Hzo6leZruPdn"}},{"cell_type":"code","source":["def visualize_alignment(alignment, src_texts=None, target_texts=None):\n","    # YOUR SOLUTION HERE\n","    # BEGIN ALIGNMENT\n","    for i in range(len(alignment)):\n","        s_idx, t_idx = alignment[i]\n","        # print(s_idx, t_idx)\n","        print(f\"{src_texts[s_idx]} ==> {target_texts[t_idx]}\")\n","    # END ALIGNMENT\n","\n","aligned_data = [\n","    (['klein', 'ist', 'das', 'haus'], ['the', 'house', 'is', 'small']),\n","    (['das', 'haus', 'ist', 'ja', 'groß'], ['the', 'house', 'is', 'big']),\n","    (['das', 'buch', 'ist', 'ja', 'klein'], ['the', 'book', 'is', 'small']),\n","    (['das', 'haus'], ['the', 'house']),\n","    (['das', 'buch'], ['the', 'book']),\n","    (['ein', 'buch'], ['a', 'book'])\n","]\n","ibm = IBMModel1(aligned_data)\n","ibm.train()\n","alignment = ibm.get_alignment(['klein', 'ist', 'das', 'haus'], ['the', 'house', 'is', 'small'])\n","visualize_alignment(alignment, ['klein', 'ist', 'das', 'haus'], ['the', 'house', 'is', 'small'])"],"metadata":{"id":"wjjeWcVLuPdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677477308112,"user_tz":480,"elapsed":6,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"c29e4c84-0c23-4a13-b3af-2f642b1f2ad4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 1667.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Iteration: 0 | Perplexity: 11073029760800.064\n","Iteration: 1 | Perplexity: 128651404090.76886\n","Iteration: 2 | Perplexity: 37310128868.217896\n","Iteration: 3 | Perplexity: 17088090612.401613\n","Iteration: 4 | Perplexity: 10288974458.354176\n","Iteration: 5 | Perplexity: 7332416600.185504\n","Iteration: 6 | Perplexity: 5807037578.352356\n","Iteration: 7 | Perplexity: 4923823037.108423\n","Iteration: 8 | Perplexity: 4370929877.625765\n","Iteration: 9 | Perplexity: 4005806888.655537\n","Iteration: 10 | Perplexity: 3755272702.3372397\n","klein ==> small\n","ist ==> is\n","das ==> the\n","haus ==> house\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["We'll now run the IBM model on a significantly larger dataset to showcase its failure modes:"],"metadata":{"id":"hmxpgwEruPdo"}},{"cell_type":"code","source":["!pip install sentencepiece torchtext==0.8.1\n","import sentencepiece\n","import torchtext"],"metadata":{"execution":{"iopub.status.busy":"2022-02-11T20:06:12.445711Z","iopub.execute_input":"2022-02-11T20:06:12.446028Z","iopub.status.idle":"2022-02-11T20:07:21.554165Z","shell.execute_reply.started":"2022-02-11T20:06:12.445985Z","shell.execute_reply":"2022-02-11T20:07:21.553432Z"},"trusted":true,"id":"aWyB-MGduPdo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677477391336,"user_tz":480,"elapsed":78942,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"45d03f1d-a18b-401d-fbfd-9eaa046c2074"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchtext==0.8.1\n","  Downloading torchtext-0.8.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.8.1) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.8.1) (2.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.8.1) (4.64.1)\n","Collecting torch==1.7.1\n","  Downloading torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1->torchtext==0.8.1) (4.5.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.8.1) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.8.1) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.8.1) (2.10)\n","Installing collected packages: sentencepiece, torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.14.1\n","    Uninstalling torchtext-0.14.1:\n","      Successfully uninstalled torchtext-0.14.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.7.1 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.7.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed sentencepiece-0.1.97 torch-1.7.1 torchtext-0.8.1\n"]}]},{"cell_type":"code","source":["# Load the Multi30K translation dataset:\n","extensions = [\".de\", \".en\"]\n","source_field = torchtext.data.Field(tokenize=lambda x: x)\n","target_field = torchtext.data.Field(tokenize=lambda x: x)\n","training_data, validation_data, test_data = torchtext.datasets.Multi30k.splits(\n","    extensions, [source_field, target_field], root=\".\")"],"metadata":{"execution":{"iopub.status.busy":"2022-02-11T20:07:21.55607Z","iopub.execute_input":"2022-02-11T20:07:21.556417Z","iopub.status.idle":"2022-02-11T20:07:26.26864Z","shell.execute_reply.started":"2022-02-11T20:07:21.556373Z","shell.execute_reply":"2022-02-11T20:07:26.267744Z"},"trusted":true,"id":"YtSTfsDwuPdo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677477396478,"user_tz":480,"elapsed":5147,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"645b75dd-399e-4b9c-9249-160cb40451c0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["downloading training.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 682kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading validation.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 243kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading mmt_task1_test2016.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 242kB/s]\n","/usr/local/lib/python3.8/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"]}]},{"cell_type":"code","source":["def preprocess(sentence):\n","    sentence = sentence.translate(str.maketrans('', '', string.punctuation)) # strip punctuation\n","    return sentence.strip().lower().split()\n","\n","aligned_data = []\n","for example in training_data[:1000]:\n","    source = preprocess(example.src)\n","    target = preprocess(example.trg)\n","    aligned_data.append((source, target))\n","\n","ibm = IBMModel1(aligned_data, compute_perplexity=False)\n","ibm.train()\n","with open(\"multi30k_alignments.pkl\", \"wb\") as outfile:\n","    pickle.dump(ibm.translation_probs, outfile, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"execution":{"iopub.status.busy":"2022-02-11T20:27:56.557834Z","iopub.execute_input":"2022-02-11T20:27:56.558251Z","iopub.status.idle":"2022-02-11T20:29:20.564518Z","shell.execute_reply.started":"2022-02-11T20:27:56.5582Z","shell.execute_reply":"2022-02-11T20:29:20.563594Z"},"trusted":true,"id":"bSX_GfvquPdo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677477507786,"user_tz":480,"elapsed":111314,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"dc706f66-63c5-488f-e921-d33c38ba5eb2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [01:45<00:00, 10.54s/it]\n"]}]},{"cell_type":"code","source":["# Making sure the model learned something:\n","examples = [\n","    (\"hund\", \"dog\"),\n","    (\"hund\", \"cat\"),\n","    (\"ein\", \"a\"),\n","    (\"ein\", \"the\"),\n","    (\"frau\", \"woman\"),\n","    (\"frau\", \"man\"),\n","]\n","\n","\n","for example in examples:\n","    print(str(example) + \": \" + str(ibm.translation_probs[example]))"],"metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:05:19.137386Z","iopub.execute_input":"2022-02-11T21:05:19.138073Z","iopub.status.idle":"2022-02-11T21:05:19.147051Z","shell.execute_reply.started":"2022-02-11T21:05:19.13803Z","shell.execute_reply":"2022-02-11T21:05:19.146357Z"},"trusted":true,"id":"qbXsgzyFuPdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677477507787,"user_tz":480,"elapsed":33,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"32c0d699-1a0b-4c9d-a9d5-9fcebe25a030"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["('hund', 'dog'): 0.9765105915208369\n","('hund', 'cat'): 1.0745541756409012e-16\n","('ein', 'a'): 0.904016367677722\n","('ein', 'the'): 0.0002091328743299106\n","('frau', 'woman'): 0.9528437741343648\n","('frau', 'man'): 2.454275253390026e-07\n"]}]},{"cell_type":"markdown","source":["From this larger dataset: find at least one sentence where the IBM alignment model performs reasonably well, and find another one where it fails catastrophically, and include alignment visualizations for both examples in your report. You may want to consult a [German-English dictionary](https://www.collinsdictionary.com/us/dictionary/english-german) for this part of the problem. Provide a brief explanation for why the alignment model did poorly on the failure case."],"metadata":{"id":"DIwS6lLtuPdp"}},{"cell_type":"code","source":["print(aligned_data[3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_PqtFVixDoO","executionInfo":{"status":"ok","timestamp":1676947258669,"user_tz":480,"elapsed":127,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"f4a83bc0-7920-4f20-ca00-88826be2a6a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'steht', 'auf', 'einer', 'leiter', 'und', 'putzt', 'ein', 'fenster'], ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window'])\n"]}]},{"cell_type":"code","source":["de, en = aligned_data[3]\n","align = ibm.get_alignment(de, en)\n","visualize_alignment(align, de, en)\n","print(\"de:\\t\", de)\n","print(\"en:\\t\", en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2odVOVSgxFCO","executionInfo":{"status":"ok","timestamp":1677477507787,"user_tz":480,"elapsed":29,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"5ade838f-4296-4b0f-9dae-bf3c37ff306c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["ein ==> a\n","mann ==> man\n","in ==> in\n","einem ==> a\n","blauen ==> blue\n","hemd ==> shirt\n","steht ==> standing\n","auf ==> on\n","einer ==> a\n","leiter ==> ladder\n","und ==> a\n","putzt ==> cleaning\n","ein ==> a\n","fenster ==> window\n","de:\t ['ein', 'mann', 'in', 'einem', 'blauen', 'hemd', 'steht', 'auf', 'einer', 'leiter', 'und', 'putzt', 'ein', 'fenster']\n","en:\t ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window']\n"]}]},{"cell_type":"code","source":["de, en = aligned_data[9]\n","align = ibm.get_alignment(de, en)\n","visualize_alignment(align, de, en)\n","print(\"de:\\t\", de)\n","print(\"en:\\t\", en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6_cPLFfxcCP","executionInfo":{"status":"ok","timestamp":1677477507787,"user_tz":480,"elapsed":27,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"9dd25105-2dca-4f2e-ff0e-47aaf14a44b7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["jungen ==> boys\n","tanzen ==> the\n","mitten ==> the\n","in ==> in\n","der ==> the\n","nacht ==> night\n","auf ==> on\n","pfosten ==> poles\n","de:\t ['jungen', 'tanzen', 'mitten', 'in', 'der', 'nacht', 'auf', 'pfosten']\n","en:\t ['boys', 'dancing', 'on', 'poles', 'in', 'the', 'middle', 'of', 'the', 'night']\n"]}]},{"cell_type":"code","source":["print(ibm.translation_probs[('tanzen', 'dance')])\n","print(ibm.translation_probs[('tanzen', 'dancing')])\n","print(ibm.translation_probs[('tanzen', 'the')])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3fJSXdt2s_O","executionInfo":{"status":"ok","timestamp":1677477507788,"user_tz":480,"elapsed":26,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"eecd9b92-7c3c-4455-9202-03996c7d6114"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["0.294913456168628\n","0.02111680882816914\n","0.038346763508053196\n"]}]},{"cell_type":"code","source":["de, en = aligned_data[12]\n","align = ibm.get_alignment(de, en)\n","visualize_alignment(align, de, en)\n","print(\"de:\\t\", de)\n","print(\"en:\\t\", en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9EYPYT04GZC","executionInfo":{"status":"ok","timestamp":1677477507788,"user_tz":480,"elapsed":25,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"af63d161-eaae-4374-d42f-a91d74053e55"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["ein ==> a\n","schwarzer ==> black\n","hund ==> dog\n","und ==> and\n","ein ==> a\n","gefleckter ==> spotted\n","hund ==> dog\n","kämpfen ==> and\n","de:\t ['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kämpfen']\n","en:\t ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n"]}]},{"cell_type":"code","source":["de, en = aligned_data[43]\n","align = ibm.get_alignment(de, en)\n","visualize_alignment(align, de, en)\n","print(\"de:\\t\", de)\n","print(\"en:\\t\", en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ko1_lWze0L9G","executionInfo":{"status":"ok","timestamp":1677477507788,"user_tz":480,"elapsed":24,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"5d5dfac9-3ede-43fa-a063-ae959dd5cdb0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["eine ==> a\n","schöne ==> new\n","braut ==> bride\n","geht ==> walking\n","auf ==> on\n","einem ==> a\n","gehweg ==> sidewalk\n","mit ==> with\n","ihrem ==> her\n","neuen ==> new\n","ehemann ==> new\n","de:\t ['eine', 'schöne', 'braut', 'geht', 'auf', 'einem', 'gehweg', 'mit', 'ihrem', 'neuen', 'ehemann']\n","en:\t ['a', 'beautiful', 'bride', 'walking', 'on', 'a', 'sidewalk', 'with', 'her', 'new', 'husband']\n"]}]},{"cell_type":"code","source":["print(ibm.translation_probs[('ehemann', 'husband')])\n","print(ibm.translation_probs[('ehemann', 'new')])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7IrtGst0T9D","executionInfo":{"status":"ok","timestamp":1677477507788,"user_tz":480,"elapsed":23,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"2e4df7aa-3869-46ba-8703-a9c3e88a5a72"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["0.28219773889850386\n","0.28219773889850386\n"]}]},{"cell_type":"code","source":["de, en = aligned_data[34]\n","align = ibm.get_alignment(de, en)\n","visualize_alignment(align, de, en)\n","print(\"de:\\t\", de)\n","print(\"en:\\t\", en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnjxVsTl0cml","executionInfo":{"status":"ok","timestamp":1677477507788,"user_tz":480,"elapsed":21,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}},"outputId":"db21e2aa-1ec0-4450-beca-23389f8a7e5a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["eine ==> a\n","person ==> person\n","fährt ==> riding\n","auf ==> on\n","einer ==> a\n","verschneiten ==> snowy\n","straße ==> road\n","fahrrad ==> bike\n","de:\t ['eine', 'person', 'fährt', 'auf', 'einer', 'verschneiten', 'straße', 'fahrrad']\n","en:\t ['a', 'person', 'riding', 'a', 'bike', 'on', 'a', 'snowy', 'road']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CSZmmpug0iJl","executionInfo":{"status":"ok","timestamp":1677477507789,"user_tz":480,"elapsed":21,"user":{"displayName":"Yorick Chern","userId":"04667733807414025524"}}},"execution_count":15,"outputs":[]}]}